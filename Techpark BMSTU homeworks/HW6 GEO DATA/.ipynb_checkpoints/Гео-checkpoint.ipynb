{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UhuSr3sqtqH5",
    "outputId": "50034771-5696-448e-97ee-6e19c41b03b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting OSMPythonTools\n",
      "  Downloading https://files.pythonhosted.org/packages/2c/81/70b878fe7b0c90c360e8ee20a12d22ae761a50bc95554342a715b32ca48e/OSMPythonTools-0.2.9.tar.gz\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from OSMPythonTools) (4.6.3)\n",
      "Collecting geojson\n",
      "  Downloading https://files.pythonhosted.org/packages/e4/8d/9e28e9af95739e6d2d2f8d4bef0b3432da40b7c3588fbad4298c1be09e48/geojson-2.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from OSMPythonTools) (4.2.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from OSMPythonTools) (3.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from OSMPythonTools) (1.19.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from OSMPythonTools) (1.1.5)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from OSMPythonTools) (3.6.4)\n",
      "Collecting pytest-sugar\n",
      "  Downloading https://files.pythonhosted.org/packages/5d/ca/0e96605e91dff95ce058a704406701d5ab8f5f3a53e8c800e5186290498c/pytest-sugar-0.9.4.tar.gz\n",
      "Collecting ujson\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/84/e039c6ffc6603f2dfe966972d345d4f650a4ffd74b18c852ece645de12ac/ujson-4.0.1-cp36-cp36m-manylinux1_x86_64.whl (179kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 5.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: xarray in /usr/local/lib/python3.6/dist-packages (from OSMPythonTools) (0.15.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->OSMPythonTools) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->OSMPythonTools) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->OSMPythonTools) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->OSMPythonTools) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->OSMPythonTools) (2018.9)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->OSMPythonTools) (1.15.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->OSMPythonTools) (1.4.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->OSMPythonTools) (0.7.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->OSMPythonTools) (1.10.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->OSMPythonTools) (20.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->OSMPythonTools) (8.6.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->OSMPythonTools) (50.3.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from pytest-sugar->OSMPythonTools) (1.1.0)\n",
      "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.6/dist-packages (from pytest-sugar->OSMPythonTools) (20.8)\n",
      "Building wheels for collected packages: OSMPythonTools, pytest-sugar\n",
      "  Building wheel for OSMPythonTools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for OSMPythonTools: filename=OSMPythonTools-0.2.9-cp36-none-any.whl size=12771 sha256=fa5937ce687eb558938a2ca04e63bc1ddedf5c79865dadbbcebd6ec5132e785b\n",
      "  Stored in directory: /root/.cache/pip/wheels/4e/65/34/afe0b46e3dbb1b3da010967781d4999084bfe5c63d7b2eeefd\n",
      "  Building wheel for pytest-sugar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pytest-sugar: filename=pytest_sugar-0.9.4-py2.py3-none-any.whl size=8971 sha256=5504014d33043745628b03baeb16d51a9980f4d621fd97a2abb76dbb61826fb8\n",
      "  Stored in directory: /root/.cache/pip/wheels/72/ac/7f/55050ee786fa4a2bb2d05dea0696eab826ff1d5b8a7dbd5883\n",
      "Successfully built OSMPythonTools pytest-sugar\n",
      "Installing collected packages: geojson, pytest-sugar, ujson, OSMPythonTools\n",
      "Successfully installed OSMPythonTools-0.2.9 geojson-2.5.0 pytest-sugar-0.9.4 ujson-4.0.1\n",
      "Collecting setuptools\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/77/e921ae5c370698762cf645797f42e6d4d7e679f705a8a9697234591808aa/setuptools-51.1.0.post20201221-py3-none-any.whl (2.0MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0MB 5.7MB/s \n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Found existing installation: setuptools 50.3.2\n",
      "    Uninstalling setuptools-50.3.2:\n",
      "      Successfully uninstalled setuptools-50.3.2\n",
      "Successfully installed setuptools-51.1.0.post20201221\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pkg_resources"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libspatialindex4v5\n",
      "The following NEW packages will be installed:\n",
      "  libspatialindex-c4v5 libspatialindex4v5\n",
      "0 upgraded, 2 newly installed, 0 to remove and 14 not upgraded.\n",
      "Need to get 270 kB of archives.\n",
      "After this operation, 1,107 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex4v5 amd64 1.8.5-5 [219 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex-c4v5 amd64 1.8.5-5 [51.7 kB]\n",
      "Fetched 270 kB in 1s (411 kB/s)\n",
      "Selecting previously unselected package libspatialindex4v5:amd64.\n",
      "(Reading database ... 144865 files and directories currently installed.)\n",
      "Preparing to unpack .../libspatialindex4v5_1.8.5-5_amd64.deb ...\n",
      "Unpacking libspatialindex4v5:amd64 (1.8.5-5) ...\n",
      "Selecting previously unselected package libspatialindex-c4v5:amd64.\n",
      "Preparing to unpack .../libspatialindex-c4v5_1.8.5-5_amd64.deb ...\n",
      "Unpacking libspatialindex-c4v5:amd64 (1.8.5-5) ...\n",
      "Setting up libspatialindex4v5:amd64 (1.8.5-5) ...\n",
      "Setting up libspatialindex-c4v5:amd64 (1.8.5-5) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n",
      "Collecting rtree\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/9d/b424a18f5443996121104817e61aadcc7a45d47fe8dcdff0a5dadd6f9a66/Rtree-0.9.5.tar.gz (44kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 2.6MB/s \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: rtree\n",
      "  Building wheel for rtree (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rtree: filename=Rtree-0.9.5-cp36-cp36m-linux_x86_64.whl size=22573 sha256=dd2e0c1e22e3111c044190efd90de4a5afafcb8437b61e8766d2418c6e4aad55\n",
      "  Stored in directory: /root/.cache/pip/wheels/94/2f/91/43fc12793530a37d764a794277edb9d63d77ac331067ffc583\n",
      "Successfully built rtree\n",
      "Installing collected packages: rtree\n",
      "Successfully installed rtree-0.9.5\n",
      "Collecting pipwin\n",
      "  Downloading https://files.pythonhosted.org/packages/08/0f/a7df1770d2dcf99898aee562d6ce866e5dc78a5ccbf4ff25231ece4c99e8/pipwin-0.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pipwin) (1.15.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pipwin) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pipwin) (20.8)\n",
      "Collecting pyprind\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/30/e76fb0c45da8aef49ea8d2a90d4e7a6877b45894c25f12fb961f009a891e/PyPrind-2.11.2-py3-none-any.whl\n",
      "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from pipwin) (0.6.2)\n",
      "Collecting beautifulsoup4>=4.9.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 6.1MB/s \n",
      "\u001b[?25hCollecting pySmartDL>=1.3.1; python_version >= \"3.4\"\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/6a/582286ea74c54363cba30413214767904f0a239e12253c3817feaf78453f/pySmartDL-1.3.4-py3-none-any.whl\n",
      "Collecting js2py\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/6a/0385641ad1b52aae5c63820277a10e500c19e40fc4df5287f161aa287020/Js2Py-0.70-py3-none-any.whl (605kB)\n",
      "\u001b[K     |████████████████████████████████| 614kB 22.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pipwin) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pipwin) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pipwin) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pipwin) (1.24.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->pipwin) (2.4.7)\n",
      "Collecting soupsieve>1.2; python_version >= \"3.0\"\n",
      "  Downloading https://files.pythonhosted.org/packages/02/fb/1c65691a9aeb7bd6ac2aa505b84cb8b49ac29c976411c6ab3659425e045f/soupsieve-2.1-py3-none-any.whl\n",
      "Collecting pyjsparser>=2.5.1\n",
      "  Downloading https://files.pythonhosted.org/packages/48/ef/c72abcfa2c6accd03e7c89c400790fc3d908c5804d50a7c4e9ceabd74d23/pyjsparser-2.7.1.tar.gz\n",
      "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.6/dist-packages (from js2py->pipwin) (1.5.1)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from tzlocal>=1.2->js2py->pipwin) (2018.9)\n",
      "Building wheels for collected packages: pyjsparser\n",
      "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-cp36-none-any.whl size=25999 sha256=120b56e0ae39ff66f38be5379e890d5689786e95d939cbdcebdb66c384fbe484\n",
      "  Stored in directory: /root/.cache/pip/wheels/a2/73/e6/3e433f3fd78257c3f971baf8cc9001cc0c4797268c61751e89\n",
      "Successfully built pyjsparser\n",
      "Installing collected packages: pyprind, soupsieve, beautifulsoup4, pySmartDL, pyjsparser, js2py, pipwin\n",
      "  Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "Successfully installed beautifulsoup4-4.9.3 js2py-0.70 pipwin-0.5.0 pySmartDL-1.3.4 pyjsparser-2.7.1 pyprind-2.11.2 soupsieve-2.1\n",
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/eb/4a3642e971f404d69d4f6fa3885559d67562801b99d7592487f1ecc4e017/pip-20.3.3-py2.py3-none-any.whl (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 5.8MB/s \n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.3.1\n",
      "    Uninstalling pip-19.3.1:\n",
      "      Successfully uninstalled pip-19.3.1\n",
      "Successfully installed pip-20.3.3\n",
      "Collecting git+git://github.com/geopandas/geopandas.git\n",
      "  Cloning git://github.com/geopandas/geopandas.git to /tmp/pip-req-build-3y4dzfgj\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from geopandas==0.8.0+73.g1ef9242) (1.1.5)\n",
      "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.6/dist-packages (from geopandas==0.8.0+73.g1ef9242) (1.7.1)\n",
      "Collecting fiona>=1.8\n",
      "  Downloading Fiona-1.8.18-cp36-cp36m-manylinux1_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 230 kB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas==0.8.0+73.g1ef9242) (1.15.0)\n",
      "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas==0.8.0+73.g1ef9242) (7.1.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas==0.8.0+73.g1ef9242) (2020.12.5)\n",
      "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas==0.8.0+73.g1ef9242) (20.3.0)\n",
      "Collecting click-plugins>=1.0\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting cligj>=0.5\n",
      "  Downloading cligj-0.7.1-py3-none-any.whl (7.1 kB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->geopandas==0.8.0+73.g1ef9242) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->geopandas==0.8.0+73.g1ef9242) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->geopandas==0.8.0+73.g1ef9242) (2018.9)\n",
      "Collecting pyproj>=2.2.0\n",
      "  Downloading pyproj-3.0.0.post1-cp36-cp36m-manylinux2010_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 70.8 MB/s \n",
      "\u001b[?25hCollecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: geopandas\n",
      "  Building wheel for geopandas (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for geopandas: filename=geopandas-0.8.0+73.g1ef9242-py2.py3-none-any.whl size=973544 sha256=d1e926c4701b9992b0c1bb07d17df9d232a2ede104385e29e8123c33e3a7aeab\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wrebiy__/wheels/e7/83/8b/b0820f79d4683dc1af4f6f664cbef2c55c612647f22abee7bc\n",
      "Successfully built geopandas\n",
      "Installing collected packages: munch, cligj, click-plugins, pyproj, fiona, geopandas\n",
      "Successfully installed click-plugins-1.1.1 cligj-0.7.1 fiona-1.8.18 geopandas-0.8.0+73.g1ef9242 munch-2.5.0 pyproj-3.0.0.post1\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libspatialindex-c4v5 is already the newest version (1.8.5-5).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n",
      "Collecting pysal\n",
      "  Downloading pysal-2.3.0.tar.gz (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 5.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.25 in /usr/local/lib/python3.6/dist-packages (from pysal) (1.24.3)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pysal) (3.6.4)\n",
      "Requirement already satisfied: coverage in /usr/local/lib/python3.6/dist-packages (from pysal) (3.7.1)\n",
      "Collecting spvcm==0.3.0\n",
      "  Downloading spvcm-0.3.0.tar.gz (5.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 16.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spvcm==0.3.0->pysal) (1.19.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from spvcm==0.3.0->pysal) (1.4.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from spvcm==0.3.0->pysal) (1.1.5)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from spvcm==0.3.0->pysal) (0.11.0)\n",
      "Collecting access>=1.1.1\n",
      "  Downloading access-1.1.3-py3-none-any.whl (21 kB)\n",
      "Collecting esda>=2.3.1\n",
      "  Downloading esda-2.3.1.tar.gz (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 7.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from esda>=2.3.1->pysal) (0.22.2.post1)\n",
      "Collecting giddy>=2.3.3\n",
      "  Downloading giddy-2.3.3-py3-none-any.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 6.7 MB/s \n",
      "\u001b[?25hCollecting inequality>=1.0.0\n",
      "  Downloading inequality-1.0.0.tar.gz (11 kB)\n",
      "Collecting libpysal>=4.3.0\n",
      "  Downloading libpysal-4.3.0.tar.gz (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 39.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from libpysal>=4.3.0->pysal) (4.9.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from libpysal>=4.3.0->pysal) (2.23.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from libpysal>=4.3.0->pysal) (2.11.2)\n",
      "Collecting mapclassify>=2.3.0\n",
      "  Downloading mapclassify-2.4.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from mapclassify>=2.3.0->pysal) (2.5)\n",
      "Collecting mgwr>=2.1.1\n",
      "  Downloading mgwr-2.1.2.tar.gz (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 555 kB/s \n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->spvcm==0.3.0->pysal) (2018.9)\n",
      "Collecting pointpats>=2.2.0\n",
      "  Downloading pointpats-2.2.0.tar.gz (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 3.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pointpats>=2.2.0->pysal) (3.2.2)\n",
      "Collecting opencv-contrib-python>=4.2.0\n",
      "  Downloading opencv_contrib_python-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (55.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 55.7 MB 15 kB/s \n",
      "\u001b[?25hCollecting python-dateutil<=2.8.0\n",
      "  Downloading python_dateutil-2.8.0-py2.py3-none-any.whl (226 kB)\n",
      "\u001b[K     |████████████████████████████████| 226 kB 53.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<=2.8.0->pysal) (1.15.0)\n",
      "Collecting quantecon>=0.4.7\n",
      "  Downloading quantecon-0.4.8-py3-none-any.whl (230 kB)\n",
      "\u001b[K     |████████████████████████████████| 230 kB 52.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.6/dist-packages (from quantecon>=0.4.7->giddy>=2.3.3->pysal) (1.1.1)\n",
      "Requirement already satisfied: numba>=0.38 in /usr/local/lib/python3.6/dist-packages (from quantecon>=0.4.7->giddy>=2.3.3->pysal) (0.48.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38->quantecon>=0.4.7->giddy>=2.3.3->pysal) (51.1.0.post20201221)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38->quantecon>=0.4.7->giddy>=2.3.3->pysal) (0.31.0)\n",
      "Collecting segregation>=1.3.0\n",
      "  Downloading segregation-1.4.0-py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 1.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: geopandas in /usr/local/lib/python3.6/dist-packages (from segregation>=1.3.0->pysal) (0.8.0+73.g1ef9242)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from segregation>=1.3.0->pysal) (4.41.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->esda>=2.3.1->pysal) (1.0.0)\n",
      "Collecting spaghetti>=1.5.0\n",
      "  Downloading spaghetti-1.5.3-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: rtree in /usr/local/lib/python3.6/dist-packages (from spaghetti>=1.5.0->pysal) (0.9.5)\n",
      "Collecting spglm>=1.0.7\n",
      "  Downloading spglm-1.0.8.tar.gz (37 kB)\n",
      "Collecting spint>=1.0.6\n",
      "  Downloading spint-1.0.7.tar.gz (28 kB)\n",
      "Collecting splot>=1.1.3\n",
      "  Downloading splot-1.1.3.tar.gz (34 kB)\n",
      "Requirement already satisfied: descartes in /usr/local/lib/python3.6/dist-packages (from splot>=1.1.3->pysal) (1.1.0)\n",
      "Requirement already satisfied: fiona>=1.8 in /usr/local/lib/python3.6/dist-packages (from geopandas->segregation>=1.3.0->pysal) (1.8.18)\n",
      "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.6/dist-packages (from geopandas->segregation>=1.3.0->pysal) (1.7.1)\n",
      "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from geopandas->segregation>=1.3.0->pysal) (3.0.0.post1)\n",
      "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas->segregation>=1.3.0->pysal) (7.1.2)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas->segregation>=1.3.0->pysal) (1.1.1)\n",
      "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas->segregation>=1.3.0->pysal) (2.5.0)\n",
      "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas->segregation>=1.3.0->pysal) (20.3.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas->segregation>=1.3.0->pysal) (2020.12.5)\n",
      "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas->segregation>=1.3.0->pysal) (0.7.1)\n",
      "Collecting spreg>=1.1.1\n",
      "  Downloading spreg-1.1.2.post1-py3-none-any.whl (265 kB)\n",
      "\u001b[K     |████████████████████████████████| 265 kB 57.2 MB/s \n",
      "\u001b[?25hCollecting tobler>=0.3.1\n",
      "  Downloading tobler-0.4.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from tobler>=0.3.1->pysal) (0.10.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.6/dist-packages (from beautifulsoup4->libpysal>=4.3.0->pysal) (2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->libpysal>=4.3.0->pysal) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pointpats>=2.2.0->pysal) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pointpats>=2.2.0->pysal) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pointpats>=2.2.0->pysal) (1.3.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->mapclassify>=2.3.0->pysal) (4.4.2)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pysal) (1.10.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pysal) (8.6.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pysal) (1.4.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pysal) (0.7.1)\n",
      "Collecting pytest-cov\n",
      "  Downloading pytest_cov-2.10.1-py2.py3-none-any.whl (19 kB)\n",
      "Collecting coverage\n",
      "  Downloading coverage-5.3.1-cp36-cp36m-manylinux2010_x86_64.whl (241 kB)\n",
      "\u001b[K     |████████████████████████████████| 241 kB 59.8 MB/s \n",
      "\u001b[?25hCollecting pytest\n",
      "  Downloading pytest-6.2.1-py3-none-any.whl (279 kB)\n",
      "\u001b[K     |████████████████████████████████| 279 kB 52.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from pytest->pysal) (0.10.2)\n",
      "  Downloading pytest-6.2.0-py3-none-any.whl (279 kB)\n",
      "\u001b[K     |████████████████████████████████| 279 kB 57.3 MB/s \n",
      "\u001b[?25h  Downloading pytest-6.1.2-py3-none-any.whl (272 kB)\n",
      "\u001b[K     |████████████████████████████████| 272 kB 61.1 MB/s \n",
      "\u001b[?25h  Downloading pytest-6.1.1-py3-none-any.whl (272 kB)\n",
      "\u001b[K     |████████████████████████████████| 272 kB 47.9 MB/s \n",
      "\u001b[?25h  Downloading pytest-6.1.0-py3-none-any.whl (272 kB)\n",
      "\u001b[K     |████████████████████████████████| 272 kB 67.4 MB/s \n",
      "\u001b[?25h  Downloading pytest-6.0.2-py3-none-any.whl (270 kB)\n",
      "\u001b[K     |████████████████████████████████| 270 kB 75.3 MB/s \n",
      "\u001b[?25h  Downloading pytest-6.0.1-py3-none-any.whl (270 kB)\n",
      "\u001b[K     |████████████████████████████████| 270 kB 59.9 MB/s \n",
      "\u001b[?25h  Downloading pytest-6.0.0-py3-none-any.whl (270 kB)\n",
      "\u001b[K     |████████████████████████████████| 270 kB 58.1 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.4.3-py3-none-any.whl (248 kB)\n",
      "\u001b[K     |████████████████████████████████| 248 kB 68.8 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.4.2-py3-none-any.whl (247 kB)\n",
      "\u001b[K     |████████████████████████████████| 247 kB 60.6 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.4.1-py3-none-any.whl (246 kB)\n",
      "\u001b[K     |████████████████████████████████| 246 kB 80.4 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.4.0-py3-none-any.whl (247 kB)\n",
      "\u001b[K     |████████████████████████████████| 247 kB 66.7 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.3.5-py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 62.3 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.3.4-py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 38.0 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.3.3-py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 49.3 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.3.2-py3-none-any.whl (234 kB)\n",
      "\u001b[K     |████████████████████████████████| 234 kB 68.5 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.3.1-py3-none-any.whl (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 63.5 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.3.0-py3-none-any.whl (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 50.6 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.2.4-py3-none-any.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 65.8 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.2.3-py3-none-any.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 51.5 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.2.2-py3-none-any.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 53.8 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.2.1-py3-none-any.whl (226 kB)\n",
      "\u001b[K     |████████████████████████████████| 226 kB 56.9 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.2.0-py3-none-any.whl (226 kB)\n",
      "\u001b[K     |████████████████████████████████| 226 kB 59.5 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 75.9 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.1.2-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 82.7 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.1.1-py3-none-any.whl (223 kB)\n",
      "\u001b[K     |████████████████████████████████| 223 kB 83.4 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.1.0-py3-none-any.whl (223 kB)\n",
      "\u001b[K     |████████████████████████████████| 223 kB 81.6 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.0.1-py3-none-any.whl (221 kB)\n",
      "\u001b[K     |████████████████████████████████| 221 kB 53.2 MB/s \n",
      "\u001b[?25h  Downloading pytest-5.0.0-py3-none-any.whl (221 kB)\n",
      "\u001b[K     |████████████████████████████████| 221 kB 54.9 MB/s \n",
      "\u001b[?25h  Downloading pytest-4.6.11-py2.py3-none-any.whl (231 kB)\n",
      "\u001b[K     |████████████████████████████████| 231 kB 41.5 MB/s \n",
      "\u001b[?25h  Downloading pytest-4.6.10-py2.py3-none-any.whl (231 kB)\n",
      "\u001b[K     |████████████████████████████████| 231 kB 48.9 MB/s \n",
      "\u001b[?25h  Downloading pytest-4.6.9-py2.py3-none-any.whl (231 kB)\n",
      "\u001b[K     |████████████████████████████████| 231 kB 57.7 MB/s \n",
      "\u001b[?25h  Downloading pytest-4.6.8-py2.py3-none-any.whl (230 kB)\n",
      "\u001b[K     |████████████████████████████████| 230 kB 63.2 MB/s \n",
      "\u001b[?25h  Downloading pytest-4.6.7-py2.py3-none-any.whl (230 kB)\n",
      "\u001b[K     |████████████████████████████████| 230 kB 62.6 MB/s \n",
      "\u001b[?25h  Downloading pytest-4.6.6-py2.py3-none-any.whl (230 kB)\n",
      "\u001b[K     |████████████████████████████████| 230 kB 55.7 MB/s \n",
      "\u001b[?25h  Downloading pytest-4.6.5-py2.py3-none-any.whl (230 kB)\n",
      "\u001b[K     |████████████████████████████████| 230 kB 66.3 MB/s \n",
      "\u001b[?25h  Downloading pytest-4.6.4-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[K     |████████████████████████████████| 229 kB 63.1 MB/s \n",
      "\u001b[?25h  Downloading pytest-4.6.3-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[K     |████████████████████████████████| 229 kB 62.6 MB/s \n",
      "\u001b[?25h  Downloading pytest-4.6.2-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[K     |████████████████████████████████| 229 kB 50.5 MB/s \n",
      "\u001b[?25h  Downloading pytest-4.6.1-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[K     |████████████████████████████████| 229 kB 74.3 MB/s \n",
      "\u001b[?25h  Downloading pytest-4.6.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[K     |████████████████████████████████| 229 kB 81.6 MB/s \n",
      "\u001b[?25hINFO: pip is looking at multiple versions of coverage to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting coverage\n",
      "  Downloading coverage-5.3-cp36-cp36m-manylinux1_x86_64.whl (229 kB)\n",
      "\u001b[K     |████████████████████████████████| 229 kB 72.9 MB/s \n",
      "\u001b[?25h  Downloading coverage-5.2.1-cp36-cp36m-manylinux1_x86_64.whl (229 kB)\n",
      "\u001b[K     |████████████████████████████████| 229 kB 74.0 MB/s \n",
      "\u001b[?25h  Downloading coverage-5.2-cp36-cp36m-manylinux1_x86_64.whl (229 kB)\n",
      "\u001b[K     |████████████████████████████████| 229 kB 81.4 MB/s \n",
      "\u001b[?25h  Downloading coverage-5.1-cp36-cp36m-manylinux1_x86_64.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 57.7 MB/s \n",
      "\u001b[?25h  Downloading coverage-5.0.4-cp36-cp36m-manylinux1_x86_64.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 79.3 MB/s \n",
      "\u001b[?25h  Downloading coverage-5.0.3-cp36-cp36m-manylinux1_x86_64.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 68.1 MB/s \n",
      "\u001b[?25h  Downloading coverage-5.0.2-cp36-cp36m-manylinux1_x86_64.whl (226 kB)\n",
      "\u001b[K     |████████████████████████████████| 226 kB 81.2 MB/s \n",
      "\u001b[?25hINFO: pip is looking at multiple versions of coverage to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading coverage-5.0.1-cp36-cp36m-manylinux1_x86_64.whl (226 kB)\n",
      "\u001b[K     |████████████████████████████████| 226 kB 74.8 MB/s \n",
      "\u001b[?25h  Downloading coverage-5.0-cp36-cp36m-manylinux1_x86_64.whl (226 kB)\n",
      "\u001b[K     |████████████████████████████████| 226 kB 55.8 MB/s \n",
      "\u001b[?25h  Downloading coverage-4.5.4-cp36-cp36m-manylinux1_x86_64.whl (205 kB)\n",
      "\u001b[K     |████████████████████████████████| 205 kB 46.7 MB/s \n",
      "\u001b[?25h  Downloading coverage-4.5.3-cp36-cp36m-manylinux1_x86_64.whl (205 kB)\n",
      "\u001b[K     |████████████████████████████████| 205 kB 47.7 MB/s \n",
      "\u001b[?25h  Downloading coverage-4.5.2-cp36-cp36m-manylinux1_x86_64.whl (205 kB)\n",
      "\u001b[K     |████████████████████████████████| 205 kB 39.0 MB/s \n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
      "  Downloading coverage-4.5.1-cp36-cp36m-manylinux1_x86_64.whl (202 kB)\n",
      "\u001b[K     |████████████████████████████████| 202 kB 64.3 MB/s \n",
      "\u001b[?25h  Downloading coverage-4.5-cp36-cp36m-manylinux1_x86_64.whl (202 kB)\n",
      "\u001b[K     |████████████████████████████████| 202 kB 81.2 MB/s \n",
      "\u001b[?25h  Downloading coverage-4.4.2-cp36-cp36m-manylinux1_x86_64.whl (197 kB)\n",
      "\u001b[K     |████████████████████████████████| 197 kB 59.2 MB/s \n",
      "\u001b[?25h  Downloading coverage-4.4.1-cp36-cp36m-manylinux1_x86_64.whl (196 kB)\n",
      "\u001b[K     |████████████████████████████████| 196 kB 49.1 MB/s \n",
      "\u001b[?25h  Downloading coverage-4.4-cp36-cp36m-manylinux1_x86_64.whl (196 kB)\n",
      "\u001b[K     |████████████████████████████████| 196 kB 79.3 MB/s \n",
      "\u001b[?25hINFO: pip is looking at multiple versions of pytest-cov to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pytest-cov\n",
      "  Downloading pytest_cov-2.10.0-py2.py3-none-any.whl (19 kB)\n",
      "  Downloading pytest_cov-2.9.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting rasterio\n",
      "  Downloading rasterio-1.1.8-1-cp36-cp36m-manylinux1_x86_64.whl (18.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 18.3 MB 163 kB/s \n",
      "\u001b[?25hCollecting snuggs>=1.4.1\n",
      "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
      "Collecting affine\n",
      "  Downloading affine-2.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting rasterstats\n",
      "  Downloading rasterstats-0.15.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->libpysal>=4.3.0->pysal) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->libpysal>=4.3.0->pysal) (3.0.4)\n",
      "Collecting simplejson\n",
      "  Downloading simplejson-3.17.2-cp36-cp36m-manylinux2010_x86_64.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 83.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->tobler>=0.3.1->pysal) (0.5.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy->quantecon>=0.4.7->giddy>=2.3.3->pysal) (1.1.0)\n",
      "Building wheels for collected packages: pysal, spvcm, esda, inequality, libpysal, mgwr, pointpats, spglm, spint, splot\n",
      "  Building wheel for pysal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pysal: filename=pysal-2.3.0-py3-none-any.whl size=18421 sha256=c9aef56632768f226495f307f64e763671c55d8b27d8fdc7f9068fab6a934e75\n",
      "  Stored in directory: /root/.cache/pip/wheels/a4/58/e3/64917b728221e084dce53ae04815b7dd6044cd5e401054705e\n",
      "  Building wheel for spvcm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for spvcm: filename=spvcm-0.3.0-py3-none-any.whl size=5777202 sha256=5de03deaf380cd90effca8c3f94a844c3a385ad949ae6711fccf1d9d44134567\n",
      "  Stored in directory: /root/.cache/pip/wheels/98/db/80/428d77c9b5e1f1750e8723d436cbe8fb5271be139f95db1a26\n",
      "  Building wheel for esda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for esda: filename=esda-2.3.1-py3-none-any.whl size=82451 sha256=8a610e879702a2b6eda13a360af6d4f3a23bbbee0d06742e4e9f984b3058f2e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/66/fc/88/b392ec90bad78dcbef9e661d74f644b7c51a7c9c1fb4a322f6\n",
      "  Building wheel for inequality (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for inequality: filename=inequality-1.0.0-py3-none-any.whl size=11800 sha256=b18aef8a9c60a4a8d9f9c7dbaf60e1c0e3716c6a018c1315a8464761ba56cfa4\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/fc/0a/3bb902875c5f4877be9d15fda78d7a6f56c3b1266977e0e5a4\n",
      "  Building wheel for libpysal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for libpysal: filename=libpysal-4.3.0-py2.py3-none-any.whl size=2379082 sha256=43e1a63d6a0d70c609ef2b476183419c5d0e8d52d466081d75a779643b807a14\n",
      "  Stored in directory: /root/.cache/pip/wheels/be/cd/3d/aaacc149b526b84d126218231a9ce3b2d81a3d84fef477d42f\n",
      "  Building wheel for mgwr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mgwr: filename=mgwr-2.1.2-py3-none-any.whl size=46370 sha256=fc304ed7516c3e9566f089e4f202835f6f008e9a3588638e2df94b664a3ef285\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/d8/86/22f8e8ca3c23fdf39383d8515289513897af9155849072c5d4\n",
      "  Building wheel for pointpats (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pointpats: filename=pointpats-2.2.0-py3-none-any.whl size=60818 sha256=2e982d08ba97e4ca59267beeb64d544d2d8a5e3d0cbc0d4e1fbb525a4e8481c5\n",
      "  Stored in directory: /root/.cache/pip/wheels/88/cc/fa/39959725ce02c1a8bc3d9e0aa86d1511afa70a829fca9e5a9f\n",
      "  Building wheel for spglm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for spglm: filename=spglm-1.0.8-py3-none-any.whl size=38805 sha256=79205f0970e4fc75a19a74a5bc7e30f781cb2f79353ab2cf9540d2fd0abbc178\n",
      "  Stored in directory: /root/.cache/pip/wheels/28/e2/e1/568a3ad5a990334a19fec912e7238405c4dcc1f2be45009f9f\n",
      "  Building wheel for spint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for spint: filename=spint-1.0.7-py3-none-any.whl size=31370 sha256=5bf9a3c86cc8c89085e84c3f4f6bfb67fb311723aac27029e7577e684ae46b8d\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/4f/91/aac6021999d05382712702c26ab9761f19cbf496b1e4502a54\n",
      "  Building wheel for splot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for splot: filename=splot-1.1.3-py3-none-any.whl size=37865 sha256=415f0b686da6f045fe748afe9b5fb2018ff7c312640a1126da7e68d934d856b0\n",
      "  Stored in directory: /root/.cache/pip/wheels/04/e9/68/613b0f7da714523e27f8397939bcd448bd945c8b029c9672b8\n",
      "Successfully built pysal spvcm esda inequality libpysal mgwr pointpats spglm spint splot\n",
      "Installing collected packages: python-dateutil, snuggs, libpysal, affine, spreg, simplejson, rasterio, quantecon, mapclassify, esda, spglm, rasterstats, opencv-contrib-python, giddy, coverage, tobler, spvcm, splot, spint, spaghetti, segregation, pytest-cov, pointpats, mgwr, inequality, access, pysal\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: opencv-contrib-python\n",
      "    Found existing installation: opencv-contrib-python 4.1.2.30\n",
      "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
      "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
      "  Attempting uninstall: coverage\n",
      "    Found existing installation: coverage 3.7.1\n",
      "    Uninstalling coverage-3.7.1:\n",
      "      Successfully uninstalled coverage-3.7.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datascience 0.10.6 requires coverage==3.7.1, but you have coverage 5.3.1 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
      "coveralls 0.5 requires coverage<3.999,>=3.6, but you have coverage 5.3.1 which is incompatible.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Successfully installed access-1.1.3 affine-2.3.0 coverage-5.3.1 esda-2.3.1 giddy-2.3.3 inequality-1.0.0 libpysal-4.3.0 mapclassify-2.4.0 mgwr-2.1.2 opencv-contrib-python-4.4.0.46 pointpats-2.2.0 pysal-2.3.0 pytest-cov-2.9.0 python-dateutil-2.8.0 quantecon-0.4.8 rasterio-1.1.8 rasterstats-0.15.0 segregation-1.4.0 simplejson-3.17.2 snuggs-1.4.7 spaghetti-1.5.3 spglm-1.0.8 spint-1.0.7 splot-1.1.3 spreg-1.1.2.post1 spvcm-0.3.0 tobler-0.4.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "dateutil"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/geopandas/geopandas.git\n",
      "  Cloning git://github.com/geopandas/geopandas.git to /tmp/pip-req-build-dgnsplgx\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from geopandas==0.8.0+73.g1ef9242) (1.1.5)\n",
      "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.6/dist-packages (from geopandas==0.8.0+73.g1ef9242) (1.7.1)\n",
      "Requirement already satisfied: fiona>=1.8 in /usr/local/lib/python3.6/dist-packages (from geopandas==0.8.0+73.g1ef9242) (1.8.18)\n",
      "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from geopandas==0.8.0+73.g1ef9242) (3.0.0.post1)\n",
      "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas==0.8.0+73.g1ef9242) (1.15.0)\n",
      "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas==0.8.0+73.g1ef9242) (7.1.2)\n",
      "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas==0.8.0+73.g1ef9242) (0.7.1)\n",
      "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas==0.8.0+73.g1ef9242) (2.5.0)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas==0.8.0+73.g1ef9242) (1.1.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas==0.8.0+73.g1ef9242) (2020.12.5)\n",
      "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.8->geopandas==0.8.0+73.g1ef9242) (20.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->geopandas==0.8.0+73.g1ef9242) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->geopandas==0.8.0+73.g1ef9242) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->geopandas==0.8.0+73.g1ef9242) (1.19.4)\n",
      "Collecting overpy\n",
      "  Downloading overpy-0.4.tar.gz (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 387 kB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: overpy\n",
      "  Building wheel for overpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for overpy: filename=overpy-0.4-py3-none-any.whl size=45771 sha256=15da890d8836b3adb4e0d15b581fc5759b04bf611157f8db0423f360208f0f93\n",
      "  Stored in directory: /root/.cache/pip/wheels/be/26/99/bcaf5f060042530729608b5714e962d6b245f83cd986ed127b\n",
      "Successfully built overpy\n",
      "Installing collected packages: overpy\n",
      "Successfully installed overpy-0.4\n"
     ]
    }
   ],
   "source": [
    "#честно говоря, я так и не пояла, с чем это все работает, а с чем нет, поэтому оставила все\n",
    "#чекни, без чего работает, а без чего нет\n",
    "!pip install OSMPythonTools\n",
    "!pip install -U setuptools\n",
    "!apt install libspatialindex-c4v5\n",
    "!pip install rtree\n",
    "!pip install pipwin\n",
    "!pip install --upgrade pip\n",
    "!pip install git+git://github.com/geopandas/geopandas.git\n",
    "!apt install libspatialindex-c4v5\n",
    "!pip install pysal\n",
    "\n",
    "!pip install git+git://github.com/geopandas/geopandas.git\n",
    "!pip3 install overpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03En8VDFTZmn"
   },
   "source": [
    "### Задача:\n",
    "\n",
    "Прогноз продаж одной из популярных моделей [фичерфонов](https://ru.wikipedia.org/wiki/%D0%A4%D0%B8%D1%87%D0%B5%D1%80%D1%84%D0%BE%D0%BD) (на картинке ниже пример похожего устройства) в салонах МегаФона\n",
    "![](https://39.img.avito.st/640x480/8468720439.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nI-zt13rTZmn"
   },
   "source": [
    "### Исходные данные:\n",
    "\n",
    "Датасет содержит следующие поля:\n",
    "\n",
    "1. `point_id` - Индентификатор салона\n",
    "2. `lon` - Долгота точки\n",
    "3. `lat` - Широта точки\n",
    "4. `target` - Значение таргета, усредненное за несколько месяцев и отнормированное"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WyR1uaDTZmn"
   },
   "source": [
    "### Требования к решению и советы:\n",
    "\n",
    "Ниже приведен список из нескольких важных пунктов, необходимых для решения задания. Выполнение каждого из пунктов влияет на итоговую оценку. Вы можете выполнить каждый из пунктов разными способами, самым лучшим будет считаться вариант, когда всё получение и обработка данных будут реализованы на Питоне (пример: вы можете скачать данные из OSM через интерфейс на сайте overpass-turbo или с помощью библиотек `overpass`/`requests`. Оба варианта будут зачтены, но больше баллов можно заработать во втором случае)\n",
    "\n",
    "\n",
    "\n",
    "1. Салоны расположены в нескольких разных городах, вам необходимо **определить город для каждого салона** (это понадобится во многих частях задания). К этому есть разные подходы. Вы можете провести [обратное геокодирование](https://en.wikipedia.org/wiki/Reverse_geocoding) с помощью геокодера [Nominatim](https://nominatim.org/), доступного через библиотеку `geopy` примерно вот так:\n",
    "```python\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"specify_your_app_name_here\")\n",
    "location = geolocator.reverse(\"52.509669, 13.376294\")\n",
    "print(location.address)\n",
    "```\n",
    "В таком случае, вам придется обрабатывать полученную строку адреса, чтобы извлечь название города. Также вы можете скачать из OSM или найти в любом другом источнике границы административно территориальных границ России и пересечь с ними датасет с помощью `geopandas.sjoin` (этот вариант более надежный, но нужно будет разобраться с тем, как устроены границы АТД в OSM, обратите внимание на [этот тег](https://wiki.openstreetmap.org/wiki/Key:admin_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhF9k-hhTZmn"
   },
   "source": [
    "\n",
    "2. **Используйте данные OSM**: подумайте, какие объекты могут влиять на продажи фичерфонов. Гипотеза: такие телефоны покупают люди, приезжающие в город или страну ненадолго, чтобы вставить туда отдельную симкарту для роуминга. Можно попробовать использовать местоположения железнодорожных вокзалов (изучите [этот тег](https://wiki.openstreetmap.org/wiki/Tag:railway%3Dstation)). Необходимо использовать хотя бы 5 разных типов объектов из OSM. Скорее всего, вам придется качать данные OSM отдельно для разных городов (см. пример для Нью-Йорка из лекции)\n",
    "\n",
    "\n",
    "3. **Используйте разные способы генерации признаков**: описать положение салона МегаФона относительно станций метро можно разными способами - найти ***расстояние до ближайшей станции***, или же посчитать, сколько станций попадает в ***500 метровую буферную зону*** вокруг салона. Такие признаки будут нести разную информацию. Так же попробуйте поэкспериментировать с размерами буферных зон (представьте, что значат в реальности радиусы 100, 500, 1000 метров). Попробуйте посчитать расстояние до центра города, до других объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Oemp0KnTZmn"
   },
   "source": [
    "4. **Сделайте визуализации**: постройте 2-3 карты для какого нибудь из городов - как распределен в пространстве таргет, где находятся объекты, полученные вами из OSM. Можете использовать любой инструмент - обычный `plot()`, `folium`, `keplergl`. Если выберете Кеплер, обязательно сохраните в файл конфиг карты, чтобы ее можно было воспроизвести. Сделать это можно вот так:\n",
    "\n",
    "```python\n",
    "import json\n",
    "json_data = kepler_map.config\n",
    "with open('kepler_config.json', 'w') as outfile:\n",
    "    json.dump(json_data, outfile)\n",
    "```\n",
    "5. Задание не ограничено приведенными выше пунктами, попробуйте нагенерировать интересных признаков, найти в интернете дополнительные данные (в таком случае в комментарии к коду укажите ссылку на ресурс, откуда взяли данные)\n",
    "\n",
    "\n",
    "\n",
    "6. Это довольно сложная задача - датасет очень маленький, данные по своей природе довольно случайны. Поэтому место и скор на Kaggle не будут играть решающую роль в оценке, но позволят заработать дополнительные баллы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrjiNWMfTZmn"
   },
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iboXweTjTZml"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geojson\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAfpsQyCOOge"
   },
   "outputs": [],
   "source": [
    "#выгружаем данным (города)\n",
    "#лучше всего - реализуй первым методом, это параша полная что я делала - в итоге тот же результат\n",
    "\n",
    "#далее я тебе предлагю делать запросы по тегам в турбо, далее нажимаешь запустить, затем скачать json файл и прочитать, далее ориентироваться в геодатафрейме просто\n",
    "#это пример запроса для городо - но лучше геокодером, еще раз))\n",
    "\"\"\"\n",
    "[out:json];area(3600060189)->.searchArea;\n",
    "(node[\"place\"~\"city|town\"](area.searchArea);); out body geom;\n",
    ">;\n",
    "out skel qt; \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3vn3W3Mt-jD",
    "outputId": "f03d2c67-4ba7-41b0-bd9a-5c9f60245151"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nominatim] downloading data: search\n",
      "[overpass] downloading data: [timeout:600][out:json];area(3600060189)->.searchArea;(rel[\"place\"~\"city|town\"](area.searchArea);); out body geom;out skel qt geom;\n"
     ]
    }
   ],
   "source": [
    "#выгружаем данным (города)\n",
    "#здесь я тебе предлагю сделать запрос в турбо, открыть json файл и прочитать просто\n",
    "\n",
    "# в турбо забей такой запрос, запусти, скачай и прочитай\n",
    "# но лучше всего - реализуй первым методом, это параша полная что я делала - в итоге тот же результат\n",
    "\"\"\"\n",
    "[out:json];area(3600060189)->.searchArea;\n",
    "(node[\"place\"~\"city\"](area.searchArea);); out body geom;\n",
    ">;\n",
    "out skel qt; \n",
    "\"\"\"\n",
    "####################################################################3\n",
    "from OSMPythonTools.nominatim import Nominatim\n",
    "from OSMPythonTools.overpass import overpassQueryBuilder, Overpass\n",
    "\n",
    "nominatim = Nominatim()\n",
    "areaId = nominatim.query('Russia').areaId()\n",
    "overpass = Overpass()\n",
    "query = overpassQueryBuilder(area=areaId, elementType=['rel'], selector='\"place\"~\"city|town\"', out='body geom;out skel qt',includeGeometry=True)\n",
    "result = overpass.query(query,timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DR-zYuxvx8x"
   },
   "outputs": [],
   "source": [
    "##############################################################################3\n",
    "#                                  это не надо тебе, если геокодером\n",
    "##############################################################################\n",
    "\"\"\"#\"вытаскиваем\" координаты из result\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "\n",
    "result_dict = {}\n",
    "mas = []\n",
    "cnt = 0\n",
    "for i in result.elements():\n",
    "  data = {}\n",
    "  try:\n",
    "    data['name'] = i.tag('name')\n",
    "    data['region'] = i.tag('addr:region')   \n",
    "  except Exception as e:\n",
    "    #print(e)\n",
    "    pass  \n",
    "\n",
    "  mass_polygon = []  \n",
    "  try:\n",
    "    for j in range(0,len(i.geometry()['coordinates'])):\n",
    "      if len(i.geometry()['coordinates'][j])==1:\n",
    "        for k in range(0,len(i.geometry()['coordinates'][j])):\n",
    "          polygon = (Polygon(i.geometry()['coordinates'][j][k]))\n",
    "      else:\n",
    "          try:\n",
    "            for k in range(0,len(i.geometry()['coordinates'][j])):\n",
    "              polygon = (Polygon(i.geometry()['coordinates'][j][k]))\n",
    "          except Exception as e:\n",
    "            polygon = (Polygon(i.geometry()['coordinates'][j]))\n",
    "      mass_polygon.append(polygon)\n",
    "    data['geometry'] = MultiPolygon(mass_polygon)\n",
    "    mas.append(data)\n",
    "  except Exception as e:\n",
    "    pass\n",
    "    #print(e)\n",
    "result_dict [\"results\"] = mas\n",
    "gdf_polygons = gpd.GeoDataFrame(result_dict['results'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxL_dwmIU-ku"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAYZnPI2TZmn"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/gdrive/MyDrive/mf_geo_train.csv')\n",
    "test = pd.read_csv('/content/gdrive/MyDrive/mf_geo_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14fUpjQbUyn-"
   },
   "outputs": [],
   "source": [
    "#переводим в геопандас\n",
    "gdf = gpd.GeoDataFrame(train, geometry=gpd.points_from_xy(train.lon, train.lat))\n",
    "gdf_test = gpd.GeoDataFrame(test, geometry=gpd.points_from_xy(test.lon, test.lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNLjougwzpbm"
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGVZGhCMMQim"
   },
   "outputs": [],
   "source": [
    "# тут я пересекаю, но за тебя метку города поставит геокодер, далее город - big_city\n",
    "\"\"\"intersect = gpd.sjoin(gdf,gdf_polygons[['name','geometry']], op='within')\n",
    "intersect = intersect.drop(['index_right'], axis = 1)\n",
    "intersect.shape\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Msd2i-lSSinS"
   },
   "outputs": [],
   "source": [
    "\"\"\"intersect_test = gpd.sjoin(gdf_test,gdf_polygons[['name','geometry']], op='within')\n",
    "intersect_test = intersect_test.drop(['index_right'], axis = 1)\n",
    "intersect_test.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44mSkhW20XTd"
   },
   "outputs": [],
   "source": [
    "\"\"\"dif = pd.concat([intersect[['point_id', 'lon'\t,'lat','target','geometry']], gdf[['point_id', 'lon'\t,'lat','target','geometry']]]).drop_duplicates(keep=False)\n",
    "dif.plot(figsize=(15,10))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVjmMTYgm0wD"
   },
   "outputs": [],
   "source": [
    "\"\"\"dif_test = pd.concat([intersect_test[['point_id', 'lon'\t,'lat','target','geometry']], gdf_test[['point_id', 'lon'\t,'lat','target','geometry']]]).drop_duplicates(keep=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9BE2XtUT6R4"
   },
   "outputs": [],
   "source": [
    "\"\"\"#здесь для тех точек, которые \"выпали\" из нашей таблицы, записываем ближайший город\n",
    "from shapely.geometry import Point, Polygon\n",
    "import random\n",
    "from operator import itemgetter\n",
    "\n",
    "dif['name']=np.zeros(dif.shape[0])\n",
    "dif = dif.reset_index()\n",
    "cnt = 0\n",
    "for j in dif['geometry']:\n",
    "  min = gdf_polygons_short['geometry'][0][0]\n",
    "  index_min = 0\n",
    "  for i in range(len(gdf_polygons_short['geometry'])):\n",
    "    for poly in gdf_polygons_short['geometry'][i]:\n",
    "      if poly.distance(j) < min.distance(j):\n",
    "        min=poly\n",
    "        index_min = i\n",
    "  dif['name'][cnt]= gdf_polygons_short['name'][index_min]\n",
    "  cnt+=1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EzACxiPImfG"
   },
   "outputs": [],
   "source": [
    "\"\"\"dif_test['name']=np.zeros(dif_test.shape[0])\n",
    "dif_test = dif_test.reset_index()\n",
    "cnt = 0\n",
    "for j in dif_test['geometry']:\n",
    "  min = gdf_polygons_short['geometry'][0][0]\n",
    "  index_min = 0\n",
    "  for i in range(len(gdf_polygons_short['geometry'])):\n",
    "    for poly in gdf_polygons_short['geometry'][i]:\n",
    "      if poly.distance(j) < min.distance(j):\n",
    "        min=poly\n",
    "        index_min = i\n",
    "  dif_test['name'][cnt]= gdf_polygons_short['name'][index_min]\n",
    "  cnt+=1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFJMmSDGyzTb"
   },
   "outputs": [],
   "source": [
    "\"\"\"#теперь у нас все 425 точек\n",
    "new_data = pd.concat([dif,intersect])\n",
    "new_data = new_data.drop(['index'],axis = 1).reset_index()\n",
    "new_data.shape\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMFR5rRoIyo3"
   },
   "outputs": [],
   "source": [
    "\"\"\"#теперь у нас все 107 точек\n",
    "new_data_test = pd.concat([dif_test,intersect_test])\n",
    "new_data_test = new_data_test.drop(['index'],axis = 1).reset_index()\n",
    "new_data_test.shape\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRaN7o9LTjCy",
    "outputId": "ab8fb0ed-8db9-4ada-8efc-8b075c878959"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[overpass] downloading data: [timeout:600][out:json];area(3600060189)->.searchArea;(node[\"place\"~\"city|town\"](area.searchArea);); out body geom;out skel qt geom;\n"
     ]
    }
   ],
   "source": [
    "#определим расстояние до центра города\n",
    "#предположу, что для точек, находящихся в таких городах, как Щербинка, будем считать до центра Москвы \n",
    "query = overpassQueryBuilder(area=areaId, elementType=['node'], selector='\"place\"~\"city|town\"', out='body geom;out skel qt',includeGeometry=True)\n",
    "result_cities = overpass.query(query,timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VL86sDtzBhXr"
   },
   "outputs": [],
   "source": [
    "#дистанция до центра города\n",
    "from geopy import distance\n",
    "new_data['distance_centre']=np.zeros(new_data.shape[0])\n",
    "for i in range(len(new_data['point_id'])):\n",
    "  point_true = (new_data['geometry'][i].y,new_data['geometry'][i].x)\n",
    "  for j in result_cities.elements():\n",
    "    try:\n",
    "      name = j.tag('name')\n",
    "    except Exception as e:\n",
    "      name = \"\"\n",
    "    if new_data['big_city'][i] == name:\n",
    "      x = j.lat()\n",
    "      y = j.lon()\n",
    "      point = (x,y)\n",
    "      distance_new_data =  distance.distance(point_true,point).km\n",
    "      index = new_data[new_data['point_id']==new_data['point_id'][i]].index.values.astype(int)[0]\n",
    "      new_data['distance_centre'][index] = distance_new_data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfilEoYorWP6"
   },
   "outputs": [],
   "source": [
    "new_data = new_data.drop(['index'],axis = 1).reset_index()\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGGZw3OqJaQZ"
   },
   "outputs": [],
   "source": [
    "new_data_test['distance_centre']=np.zeros(new_data_test.shape[0])\n",
    "for i in range(len(new_data_test['point_id'])):\n",
    "  point_true = (new_data_test['geometry'][i].y,new_data_test['geometry'][i].x)\n",
    "  for j in result_cities.elements():\n",
    "    try:\n",
    "      name = j.tag('name')\n",
    "    except Exception as e:\n",
    "      name = \"\"\n",
    "    if new_data_test['big_city'][i] == name:\n",
    "      x = j.lat()\n",
    "      y = j.lon()\n",
    "      point = (x,y)\n",
    "      distance_new_data =  distance.distance(point_true,point).km\n",
    "      index = new_data_test[new_data_test['point_id']==new_data_test['point_id'][i]].index.values.astype(int)[0]\n",
    "      new_data_test['distance_centre'][index] = distance_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9knSnJS3RnXP"
   },
   "outputs": [],
   "source": [
    "new_data_test = new_data_test.drop(['index'],axis = 1).reset_index()\n",
    "new_data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nd3NkcSfIZmD"
   },
   "outputs": [],
   "source": [
    "tuts_tuts = gpd.sjoin(new_data,adm[['name','geometry']], op='within')\n",
    "tuts_tuts = tuts_tuts.drop(['index_right','index'],axis = 1)\n",
    "tuts_tuts = tuts_tuts.rename(columns={\"name_left\": \"city\", \"name_right\": \"region\"}).reset_index()\n",
    "tuts_tuts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFJhM42IJp2I"
   },
   "outputs": [],
   "source": [
    "tuts_tuts_test = gpd.sjoin(new_data_test,adm[['name','geometry']], op='within')\n",
    "tuts_tuts_test = tuts_tuts_test.drop(['index_right','index'],axis = 1)\n",
    "tuts_tuts_test = tuts_tuts_test.rename(columns={\"name_left\": \"city\", \"name_right\": \"region\"}).reset_index()\n",
    "tuts_tuts_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZkGaVJ3W6Mo"
   },
   "outputs": [],
   "source": [
    "#рассчитаем расстояние до ближайшего ж/д вокзала\n",
    "\n",
    "list_cities = ['Нижний Новгород', 'Москва', 'Ростов-на-Дону', 'Красноярск',\n",
    "       'Санкт-Петербург', 'Уфа', 'Казань', 'Екатеринбург',\n",
    "       'Новосибирск', 'Самара']\n",
    "\n",
    "tuts_tuts['distance_railway']=np.zeros(tuts_tuts.shape[0])\n",
    "\n",
    "def find_min(mass):\n",
    "  min = mass[0]\n",
    "  for i in mass:\n",
    "    if i < min:\n",
    "      min = i\n",
    "  return min\n",
    "\n",
    "for i in range(len(tuts_tuts['point_id'])):\n",
    "      point_true = (tuts_tuts['geometry'][i].y,tuts_tuts['geometry'][i].x)\n",
    "      mass_points =[]\n",
    "      for ii in list_cities:        \n",
    "        query = overpassQueryBuilder(area=nominatim.query(ii+',Россия').areaId(), elementType=['node'], selector='\"railway\"=\"station\"', out='body geom;out skel qt',includeGeometry=True)\n",
    "        result_cities = overpass.query(query,timeout=600)\n",
    "        for j in result_cities.elements():\n",
    "          try:\n",
    "            if j.tag('station') == None:\n",
    "              x = j.lat() \n",
    "              y = j.lon()\n",
    "              point = (x,y)\n",
    "              distance_new_data =  distance.distance(point_true,point).km\n",
    "              #print(distance_new_data)\n",
    "              mass_points.append(distance_new_data)\n",
    "          except Exception as e:\n",
    "              pass\n",
    "      if len(mass_points)>0:\n",
    "        min_dist = find_min(mass_points)\n",
    "        index = tuts_tuts[tuts_tuts['point_id']==tuts_tuts['point_id'][i]].index.values.astype(int)[0]#БАТЯ\n",
    "        tuts_tuts['distance_railway'][index] = min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPsGKE-eLDGx"
   },
   "outputs": [],
   "source": [
    "list_cities = ['Нижний Новгород', 'Москва', 'Ростов-на-Дону', 'Красноярск',\n",
    "       'Санкт-Петербург', 'Кронштадт', 'Уфа', 'Казань', 'Екатеринбург',\n",
    "       'Новосибирск', 'Самара']\n",
    "\n",
    "tuts_tuts_test['distance_railway']=np.zeros(tuts_tuts_test.shape[0])\n",
    "\n",
    "def find_min(mass):\n",
    "  min = mass[0]\n",
    "  for i in mass:\n",
    "    if i < min:\n",
    "      min = i\n",
    "  return min\n",
    "\n",
    "for i in range(len(tuts_tuts_test['point_id'])):\n",
    "      point_true = (tuts_tuts_test['geometry'][i].y,tuts_tuts_test['geometry'][i].x)\n",
    "      mass_points =[]\n",
    "      for ii in list_cities:        \n",
    "        query = overpassQueryBuilder(area=nominatim.query(ii+',Россия').areaId(), elementType=['node'], selector='\"railway\"=\"station\"', out='body geom;out skel qt',includeGeometry=True)\n",
    "        result_cities = overpass.query(query,timeout=600)\n",
    "        for j in result_cities.elements():\n",
    "          try:\n",
    "            if j.tag('station') == None:\n",
    "              x = j.lat() \n",
    "              y = j.lon()\n",
    "              point = (x,y)\n",
    "              distance_new_data =  distance.distance(point_true,point).km\n",
    "              #print(distance_new_data)\n",
    "              mass_points.append(distance_new_data)\n",
    "          except Exception as e:\n",
    "              pass\n",
    "      if len(mass_points)>0:\n",
    "        min_dist = find_min(mass_points)\n",
    "        index = tuts_tuts_test[tuts_tuts_test['point_id']==tuts_tuts_test['point_id'][i]].index.values.astype(int)[0]#БАТЯ\n",
    "        tuts_tuts_test['distance_railway'][index] = min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJgpv32yXAlJ"
   },
   "outputs": [],
   "source": [
    "#количество гостиниц в радиусе 0.5 км\n",
    "tuts_tuts['counts_hotel_500']=np.zeros(tuts_tuts.shape[0])\n",
    "radius = 0.5 # in kilometer\n",
    "for i in range(len(tuts_tuts['point_id'])):\n",
    "  query = overpassQueryBuilder(area=nominatim.query(tuts_tuts['big_city'][i]+',Россия').areaId(), elementType=['node'], selector='\"tourism\"~\"hostel|motel|hostel\"', out='body geom;out skel qt',includeGeometry=True)\n",
    "  result_cities = overpass.query(query,timeout=600)\n",
    "  center_point = [{'lat': tuts_tuts['geometry'][i].y, 'lng': tuts_tuts['geometry'][i].x}]\n",
    "  center_point_tuple = tuple(center_point[0].values()) \n",
    "  cnt = 0\n",
    "  for j in result_cities.elements():\n",
    "    test_point = [{'lat': j.lat(), 'lng': j.lon()}]      \n",
    "    test_point_tuple = tuple(test_point[0].values())\n",
    "    dis = distance.distance(center_point_tuple, test_point_tuple).km\n",
    "    if dis <= radius:\n",
    "      cnt+=1\n",
    "  tuts_tuts['counts_hotel_500'][i]=cnt\n",
    "tuts_tuts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Novo8QBjXIkE"
   },
   "outputs": [],
   "source": [
    "tuts_tuts_test['counts_hotel_500']=np.zeros(tuts_tuts_test.shape[0])\n",
    "radius = 0.5 # in kilometer\n",
    "for i in range(len(tuts_tuts_test['point_id'])):\n",
    "  query = overpassQueryBuilder(area=nominatim.query(tuts_tuts_test['big_city'][i]+',Россия').areaId(), elementType=['node'], selector='\"tourism\"~\"hostel|motel|hostel\"', out='body geom;out skel qt',includeGeometry=True)\n",
    "  result_cities = overpass.query(query,timeout=600)\n",
    "  center_point = [{'lat': tuts_tuts_test['geometry'][i].y, 'lng': tuts_tuts_test['geometry'][i].x}]\n",
    "  center_point_tuple = tuple(center_point[0].values())\n",
    "  cnt = 0\n",
    "  for j in result_cities.elements():\n",
    "    test_point = [{'lat': j.lat(), 'lng': j.lon()}]      \n",
    "    test_point_tuple = tuple(test_point[0].values())\n",
    "    dis = distance.distance(center_point_tuple, test_point_tuple).km\n",
    "    if dis <= radius:\n",
    "      cnt+=1\n",
    "  tuts_tuts_test['counts_hotel_500'][i]=cnt\n",
    "tuts_tuts_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFtxztLJ8a2j"
   },
   "outputs": [],
   "source": [
    "#посчитаем количество остановок общественного трансорта в радиусе 500 м\n",
    "#\"public_transport\"~\"platform\"\n",
    "tuts_tuts['public_transport_500']=np.zeros(tuts_tuts.shape[0])\n",
    "radius = 0.5 # in kilometer\n",
    "for i in range(len(tuts_tuts['point_id'])):\n",
    "  query = overpassQueryBuilder(area=nominatim.query(tuts_tuts['big_city'][i]+',Россия').areaId(), elementType='node', selector='\"public_transport\"~\"platform\"', out='body geom;out skel qt',includeGeometry=True)\n",
    "  result_cities = overpass.query(query,timeout=600)\n",
    "  center_point = [{'lat': tuts_tuts['geometry'][i].y, 'lng': tuts_tuts['geometry'][i].x}]\n",
    "  center_point_tuple = tuple(center_point[0].values()) #\n",
    "  cnt = 0\n",
    "  #print(len(result_cities.elements()))\n",
    "  for j in result_cities.elements():\n",
    "    test_point = [{'lat': j.lat(), 'lng': j.lon()}]   \n",
    "    test_point_tuple = tuple(test_point[0].values())\n",
    "    #print(test_point_tuple) \n",
    "    dis = distance.distance(center_point_tuple, test_point_tuple).km\n",
    "    if dis <= radius:\n",
    "      cnt+=1\n",
    "  tuts_tuts['public_transport_500'][i]=cnt\n",
    "tuts_tuts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNvbg1IzLdWA"
   },
   "outputs": [],
   "source": [
    "#\"public_transport\"~\"platform\"\n",
    "tuts_tuts_test['public_transport_500']=np.zeros(tuts_tuts_test.shape[0])\n",
    "radius = 0.5 # in kilometer\n",
    "for i in range(len(tuts_tuts_test['point_id'])):\n",
    "  query = overpassQueryBuilder(area=nominatim.query(tuts_tuts_test['big_city'][i]+',Россия').areaId(), elementType='node', selector='\"public_transport\"~\"platform\"', out='body geom;out skel qt',includeGeometry=True)\n",
    "  result_cities = overpass.query(query,timeout=600)\n",
    "  center_point = [{'lat': tuts_tuts_test['geometry'][i].y, 'lng': tuts_tuts_test['geometry'][i].x}]\n",
    "  center_point_tuple = tuple(center_point[0].values()) #\n",
    "  cnt = 0\n",
    "  for j in result_cities.elements():\n",
    "    test_point = [{'lat': j.lat(), 'lng': j.lon()}]   \n",
    "    test_point_tuple = tuple(test_point[0].values())\n",
    "    #print(test_point_tuple) \n",
    "    dis = distance.distance(center_point_tuple, test_point_tuple).km\n",
    "    if dis <= radius:\n",
    "      cnt+=1\n",
    "  tuts_tuts_test['public_transport_500'][i]=cnt\n",
    "tuts_tuts_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9eoBHcJahf5"
   },
   "outputs": [],
   "source": [
    "#посчитаем количество мест общественного питания в радиусе 500 м\n",
    "tuts_tuts['count_food']=np.zeros(tuts_tuts.shape[0])\n",
    "radius = 0.5 # in kilometer\n",
    "for i in range(len(tuts_tuts['point_id'])):\n",
    "  query = overpassQueryBuilder(area=nominatim.query(tuts_tuts['big_city'][i]+',Россия').areaId(), elementType='node', selector='\"amenity\"~\"fast_food|cafe\"', out='body geom;out skel qt',includeGeometry=True)\n",
    "  result_cities = overpass.query(query,timeout=600)\n",
    "  center_point = [{'lat': tuts_tuts['geometry'][i].y, 'lng': tuts_tuts['geometry'][i].x}]\n",
    "  center_point_tuple = tuple(center_point[0].values()) #\n",
    "  cnt = 0\n",
    "  for j in result_cities.elements():\n",
    "    test_point = [{'lat': j.lat(), 'lng': j.lon()}]   \n",
    "    test_point_tuple = tuple(test_point[0].values())\n",
    "    dis = distance.distance(center_point_tuple, test_point_tuple).km\n",
    "    if dis <= radius:\n",
    "      cnt+=1\n",
    "  tuts_tuts['count_food'][i]=cnt\n",
    "tuts_tuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtwKDSnkMF_6"
   },
   "outputs": [],
   "source": [
    "tuts_tuts_test['count_food']=np.zeros(tuts_tuts_test.shape[0])\n",
    "radius = 0.5 # in kilometer\n",
    "for i in range(len(tuts_tuts_test['point_id'])):\n",
    "  query = overpassQueryBuilder(area=nominatim.query(tuts_tuts_test['big_city'][i]+',Россия').areaId(), elementType='node', selector='\"amenity\"~\"fast_food|cafe\"', out='body geom;out skel qt',includeGeometry=True)\n",
    "  result_cities = overpass.query(query,timeout=600)\n",
    "  center_point = [{'lat': tuts_tuts_test['geometry'][i].y, 'lng': tuts_tuts_test['geometry'][i].x}]\n",
    "  center_point_tuple = tuple(center_point[0].values()) #\n",
    "  cnt = 0\n",
    "  for j in result_cities.elements():\n",
    "    test_point = [{'lat': j.lat(), 'lng': j.lon()}]   \n",
    "    test_point_tuple = tuple(test_point[0].values())\n",
    "    dis = distance.distance(center_point_tuple, test_point_tuple).km\n",
    "    if dis <= radius:\n",
    "      cnt+=1\n",
    "  tuts_tuts_test['count_food'][i]=cnt\n",
    "tuts_tuts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZo5xubMHHJf"
   },
   "outputs": [],
   "source": [
    "tuts_tuts = tuts_tuts.drop(['city','lon', 'lat', 'geometry'], axis = 1)\n",
    "tuts_tuts_test = tuts_tuts_test.drop(['city','lon', 'lat', 'geometry'], axis = 1)\n",
    "tuts_tuts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFj0VJ85TZmp"
   },
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXQu_DEVBgHv"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoZn1GGFQP9K"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(tuts_tuts.drop('target', axis=1), tuts_tuts[['target']])\n",
    "model = LinearRegression().fit(X_train.drop('point_id', axis=1), y_train)\n",
    "y_predict =  model.predict(X_valid.drop('point_id', axis=1))\n",
    "mean_absolute_error(y_valid, model.predict(X_valid.drop('point_id', axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4I3Zj01Xxhd"
   },
   "outputs": [],
   "source": [
    "targ = pd.DataFrame(tuts_tuts_test['point_id'])\n",
    "targ['target'] = model.predict(tuts_tuts_test.drop(['point_id', 'target'], axis=1))\n",
    "\n",
    "targ.to_csv('g1_vyb.csv', encoding = 'utf-8', index=False)\n",
    "targ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEdSS4-fTZmp"
   },
   "source": [
    "### Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-k79Iq6TZmp"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission['target'] = model.predict(X_valid.drop('point_id', axis=1))\n",
    "submission.to_csv('my_submission_01.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Гео.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
